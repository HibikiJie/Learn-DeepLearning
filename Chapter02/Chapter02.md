## Chapter02

二、卷积神经网络

![img](D:\Learn-DeepLearning\image\juanji.jpg)

上一章，全连接网络的结构如上图所示。

然而全连接神经网络是有，缺陷的。如果使用全连接来识别一章图片时，首层的神经元个数达到了wXh的个数，假设图片为200X200，首层的神经元个数便达到了，四万个。这极大的增加了内存占用，和计算的次数。因此，在处理图像时，计算速度慢，效果差。

![img](https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=2448747360,1280135558&fm=15&gp=0.jpg)

卷积过程是，卷积核在图片上扫描，去出和核大小一样的一块区域，相乘再求和。然后又向左移动一步。一排卷积完成，再向下走一步。直到卷积完成所有的区域。

卷积完成后的得到的图片大小为：
$$
L=\left \lfloor \frac{l+2\times Padding-(kernelsize-1)-1}{stride}+1 \right \rfloor
$$
![image-20200717151831115](D:\Learn-DeepLearning\image\image-20200717151831115.png)

一层卷积如上图所以，一张三通道的图片，通过卷积核卷积后生成一张特征图。一共有六个卷积核，共生成了六张特征图，这六张特征图，又输入给下一层。

这类似于全连接神经网络，因为输入要传给所有的卷积核，一个卷积核只输出一张特征图。如此将单个神经元升级为一个卷积核，将输出一个数字升级为输出一张图，也就是单个神经元的计算复杂度提升了。来达到减少参数量，相应的计算力需求更大，特别是并行计算。